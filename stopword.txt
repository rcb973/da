from nltk.tokenize import word_tokenize

from nltk.corpus import stopwords



paragraph_text="""Hello all, Welcome to Python Programming Academy. Python

Programming Academy is a nice platform to learn new programming skills. It is

difficult to get enrolled in this Academy."""


tokenized_words=word_tokenize(paragraph_text)


stop_words_data=set(stopwords.words("english"))


filtered_words_list=[]

for words in tokenized_words:

if words not in stop_words_data:

 filtered_words_list.append(words)

print("Tokenized Words : \n",tokenized_words,"\n")

print("Filtered Words : \n",filtered_words_list,"\n")
